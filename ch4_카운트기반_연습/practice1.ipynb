{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00873fe3",
   "metadata": {},
   "source": [
    "# 카운트 기반 문서 표현: 문서에 나타나는 단어의 빈도를 통해 문서 이해\n",
    "<hr>\n",
    "\n",
    "### 말뭉치 -> 전처리 -> 특성 집합(Vocabulary) 생성 -> 특성 벡터 생성\n",
    "### 문서에서 사용되지 않은 단어(특성)는 0값을 가짐\n",
    "### &nbsp; &nbsp; ex) vocabulary: ['사과', '바나나', '수박', '배', '키위'], 문서: ['사과', '바나나', '오이', '토마토']일 때 \n",
    "### &nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp; 결과: [1, 1, 0, 0, 0] (사과, 바나나만 카운트)\n",
    "<br/>\n",
    "\n",
    "### 단점: 문서를 표현하기 위해 너무 많은 특성(feature)을 사용하므로 그 중 극히 일부만 값을 갖는데 \n",
    "### &nbsp; &nbsp; &nbsp; &nbsp; 이처럼 대부분 값이 0인 벡터를 희소 벡터(Sparse vector)라고 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8580eb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\ing06\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "['neg/cv000_29416.txt', 'neg/cv001_19502.txt', 'neg/cv002_17424.txt', 'neg/cv003_12683.txt', 'neg/cv004_12641.txt', 'neg/cv005_29357.txt', 'neg/cv006_17022.txt', 'neg/cv007_4992.txt', 'neg/cv008_29326.txt', 'neg/cv009_29417.txt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# 영어 문서 분석 - nltk 영화 리뷰 데이터\n",
    "import nltk\n",
    "nltk.download('movie_reviews')\n",
    "\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "print(len(movie_reviews.fileids()))   # 파일 개수 출력\n",
    "print(movie_reviews.fileids()[:10])  # 파일 10개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4dac70e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리뷰 원문 가져오기\n",
    "reviews = [movie_reviews.raw(fileid) for fileid in movie_reviews.fileids()]\n",
    "\n",
    "# sklearn의 CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#cv = CountVectorizer()    #기본적인 생성 방법\n",
    "cv = CountVectorizer(max_features=1000)  # 최대 특성(단어 집합)의 수 지정\n",
    "\n",
    "#print(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2cbce14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10' 'ability' 'able' 'about' 'above' 'absolutely' 'across' 'act'\n",
      " 'acting' 'action' 'actor' 'actors' 'actress' 'actual' 'actually' 'add'\n",
      " 'after' 'again' 'against' 'age']\n"
     ]
    }
   ],
   "source": [
    "reviews_cv = cv.fit_transform(reviews)    # fit과 transform을 동시에, (fit: 단어 집합 생성, transform: 특성 벡터 생성)\n",
    "\n",
    "# 단어 집합에서 20개만 출력\n",
    "print(cv.get_feature_names_out()[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2410b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "카운트 벡터 shape:  (2000, 1000)\n",
      "  (0, 17)\t2\n",
      "  (0, 16)\t2\n",
      "  (0, 14)\t2\n",
      "  (0, 3)\t2\n",
      "  (0, 11)\t1\n",
      "  (0, 0)\t10\n"
     ]
    }
   ],
   "source": [
    "# reviews_cv는 DTM이다\n",
    "# 즉, 행: 문서, 열: 단어의 형태인 행렬\n",
    "print(\"카운트 벡터 shape: \", reviews_cv.shape)\n",
    "print(reviews_cv[0, :20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "506db0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  0  0  2  0  0  0  0  0  0  0  1  0  0  2  0  2  2  0  0]\n"
     ]
    }
   ],
   "source": [
    "# BOW 벡터로 변환\n",
    "print(reviews_cv.toarray()[0, :20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aba48f",
   "metadata": {},
   "source": [
    "<br/> <br/>\n",
    "## 한국어 텍스트 카운트 벡터 변환\n",
    "### 다음 영화 리뷰 데이터셋 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d686cf9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>돈 들인건 티가 나지만 보는 내내 하품만</td>\n",
       "      <td>1</td>\n",
       "      <td>2018.10.29</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.</td>\n",
       "      <td>10</td>\n",
       "      <td>2018.10.26</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...</td>\n",
       "      <td>8</td>\n",
       "      <td>2018.10.24</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이 정도면 볼만하다고 할 수 있음!</td>\n",
       "      <td>8</td>\n",
       "      <td>2018.10.22</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>재미있다</td>\n",
       "      <td>10</td>\n",
       "      <td>2018.10.20</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>나는 재밌게 봄</td>\n",
       "      <td>10</td>\n",
       "      <td>2018.10.14</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5점은 줄 수 없냐?</td>\n",
       "      <td>0</td>\n",
       "      <td>2018.10.10</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>헐..다 죽었어....나중에 앤트맨 보다가도 깜놀...</td>\n",
       "      <td>10</td>\n",
       "      <td>2018.10.08</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>충격 결말</td>\n",
       "      <td>9</td>\n",
       "      <td>2018.10.06</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>응집력</td>\n",
       "      <td>8</td>\n",
       "      <td>2018.10.05</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating        date  \\\n",
       "0                             돈 들인건 티가 나지만 보는 내내 하품만       1  2018.10.29   \n",
       "1       몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.      10  2018.10.26   \n",
       "2  이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...       8  2018.10.24   \n",
       "3                                이 정도면 볼만하다고 할 수 있음!       8  2018.10.22   \n",
       "4                                               재미있다      10  2018.10.20   \n",
       "5                                           나는 재밌게 봄      10  2018.10.14   \n",
       "6                                      0.5점은 줄 수 없냐?       0  2018.10.10   \n",
       "7                     헐..다 죽었어....나중에 앤트맨 보다가도 깜놀...      10  2018.10.08   \n",
       "8                                              충격 결말       9  2018.10.06   \n",
       "9                                                응집력       8  2018.10.05   \n",
       "\n",
       "    title  \n",
       "0  인피니티 워  \n",
       "1  인피니티 워  \n",
       "2  인피니티 워  \n",
       "3  인피니티 워  \n",
       "4  인피니티 워  \n",
       "5  인피니티 워  \n",
       "6  인피니티 워  \n",
       "7  인피니티 워  \n",
       "8  인피니티 워  \n",
       "9  인피니티 워  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 한글 문서 분석 - 다음 영화 리뷰 데이터셋\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/daum_movie_review.csv\")\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "873afc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['10점' '18' '1987' '1도' '1점' '1점도' '2시간' '2시간이' '2편' '5점' '6점' '7점' '8점'\n",
      " 'cg' 'cg가' 'cg는' 'cg도' 'cg만' 'good' 'of' 'ㅋㅋ' 'ㅋㅋㅋ' 'ㅋㅋㅋㅋ' 'ㅎㅎ' 'ㅎㅎㅎ'\n",
      " 'ㅜㅜ' 'ㅠㅠ' 'ㅠㅠㅠ' 'ㅡㅡ' '가는' '가는줄' '가면' '가서' '가슴' '가슴아픈' '가슴이' '가장' '가족'\n",
      " '가족과' '가족들과' '가족의' '가족이' '가지고' '간만에' '갈수록' '감독' '감독님' '감독은' '감독의' '감독이'\n",
      " '감동' '감동과' '감동도' '감동은' '감동을' '감동이' '감동입니다' '감동적' '감동적이고' '감동적인' '감사드립니다'\n",
      " '감사합니다' '감정이' '갑자기' '갔는데' '갔다가' '강철비' '강추' '강추합니다' '같고' '같네요' '같다' '같습니다'\n",
      " '같아' '같아요' '같은' '같은데' '같음' '같이' '개연성' '개연성이' '개인적으로' '거의' '겁나' '것도' '것은'\n",
      " '것을' '것이' '것이다' '겨울왕국' '결국' '결말' '결말이' '계속' '고맙습니다' '곤지암' '공포' '공포를'\n",
      " '공포영화' '관객']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features=1000)        # vocab 크기 1000\n",
    "dtm = cv.fit_transform(df['review'])\n",
    "\n",
    "print(cv.get_feature_names_out()[:100])    # 특성 집합 출력\n",
    "# 같은 단어가 들어간 경우가 너무 많음 \n",
    "# ex) '감동' -> '감동', '감동과', '감동도', '감동은', '감동을'..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "305d4635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "형태소:  ['이전', '작품', '에', '비해', '더', '화려하고', '스케일', '도', '커졌지만', '....', '전국', '맛집', '의', '음식', '들', '을', '한데', '모은', '것', '까지는', '좋았으나', '이', '걸', '모두', '한', '그릇', '에', '섞어', '버린', '듯', '한', '느낌', '...', '그래도', '다음', '작품', '을', '기대하게', '만든다', '...']\n",
      "\n",
      "명사:  ['이전', '작품', '더', '스케일', '전국', '맛집', '음식', '것', '걸', '모두', '그릇', '듯', '느낌', '다음', '작품']\n",
      "\n",
      "품사 태깅:  [('이전', 'Noun'), ('작품', 'Noun'), ('에', 'Josa'), ('비해', 'Verb'), ('더', 'Noun'), ('화려하고', 'Adjective'), ('스케일', 'Noun'), ('도', 'Josa'), ('커졌지만', 'Verb'), ('....', 'Punctuation'), ('전국', 'Noun'), ('맛집', 'Noun'), ('의', 'Josa'), ('음식', 'Noun'), ('들', 'Suffix'), ('을', 'Josa'), ('한데', 'Eomi'), ('모은', 'Verb'), ('것', 'Noun'), ('까지는', 'Josa'), ('좋았으나', 'Adjective'), ('이', 'Determiner'), ('걸', 'Noun'), ('모두', 'Noun'), ('한', 'Verb'), ('그릇', 'Noun'), ('에', 'Josa'), ('섞어', 'Verb'), ('버린', 'Verb'), ('듯', 'Noun'), ('한', 'Josa'), ('느낌', 'Noun'), ('...', 'Punctuation'), ('그래도', 'Adverb'), ('다음', 'Noun'), ('작품', 'Noun'), ('을', 'Josa'), ('기대하게', 'Adjective'), ('만든다', 'Verb'), ('...', 'Punctuation')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "t = Okt()\n",
    "\n",
    "print(\"형태소: \", t.morphs(df['review'][2]))\n",
    "print()\n",
    "print(\"명사: \", t.nouns(df['review'][2]))\n",
    "print()\n",
    "print(\"품사 태깅: \", t.pos(df['review'][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef236e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['가' '가는' '가는줄' '가면' '가서' '가슴' '가장' '가족' '가족영화' '가지' '가치' '각색' '간' '간다'\n",
      " '간만' '갈' '갈수록' '감' '감독' '감동' '감사' '감사합니다' '감상' '감성' '감정' '감탄' '갑자기' '갔는데'\n",
      " '갔다' '갔다가' '강' '강철' '강추' '같고' '같네요' '같다' '같습니다' '같아' '같아요' '같은' '같은데'\n",
      " '같음' '개' '개그' '개봉' '개연' '개인' '거' '거기' '거리' '거의' '걱정' '건' '건가' '건지' '걸'\n",
      " '겁니다' '것' '게' '겨울왕국' '결론' '결말' '경찰' '경험' '계속' '고' '고맙습니다' '고민' '고생' '곤지암'\n",
      " '곳' '공감' '공포' '공포영화' '과' '과거' '관' '관객' '관객수' '관람' '광주' '괜찮은' '교훈' '구성'\n",
      " '국내' '국민' '군인' '군함도' '굿' '권선' '귀신' '그' '그것' '그게' '그날' '그냥' '그닥' '그대로'\n",
      " '그때' '그래픽']\n"
     ]
    }
   ],
   "source": [
    "# 명사, 동사, 형용사 추출\n",
    "# 토크나이저를 만들고 CountVectorizer에 지정\n",
    "\n",
    "tag_list = ['Noun', 'Verb', 'Adjective']\n",
    "def my_tokenizer(doc):\n",
    "    return [token for token, tag in t.pos(doc)\n",
    "             if tag in tag_list]\n",
    "\n",
    "cv = CountVectorizer(max_features=1000, tokenizer=my_tokenizer)\n",
    "\n",
    "dtm = cv.fit_transform(df['review'])\n",
    "\n",
    "print(cv.get_feature_names_out()[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c207be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<14725x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 110800 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "# 벡터가 얼마나 희소(sparse)한지 계산\n",
    "print(repr(dtm))   # dtm의 shape과 실제 값이 들어있는 element 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "677ffcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007524617996604414\n"
     ]
    }
   ],
   "source": [
    "# 실제 값이 들어 있는 element를 dtm shape으로 나눠줌\n",
    "print(110800/(14725*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "89a71c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "느낌 :  1\n",
      "다음 :  1\n",
      "모두 :  1\n",
      "비해 :  1\n",
      "스케일 :  1\n",
      "작품 :  2\n"
     ]
    }
   ],
   "source": [
    "# 댓글에서 사용된 단어와 개수 출력\n",
    "print(dtm[2].toarray())\n",
    "for word, count in zip(cv.get_feature_names_out(), dtm[2].toarray()[0]):     # 3번째 댓글의 카운트 벡터\n",
    "    if count > 0 and len(word) >= 2:\n",
    "        print(word, \": \", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425fdaf0",
   "metadata": {},
   "source": [
    "<br/> <br/>\n",
    "## 코사인 유사도\n",
    "### NLTK 영화 리뷰 데이터셋에 대해 유사도 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ec245fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행렬 크기:  (1, 1000)\n",
      "유사도 행렬 크기:  (1, 2000)\n",
      "[0.9406850065028822, 0.8449222207991461, 0.8348806607881823, 0.8326052445239385, 0.8315967745603229, 0.8273858498106984, 0.8245530382632896, 0.8219627744618032, 0.820420990734705, 0.8203286730382311]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "start = len(reviews[0])//2\n",
    "\n",
    "# 첫번째 리뷰 데이터의 절반을 가져옴\n",
    "source = reviews[0][-start:]\n",
    "\n",
    "source_cv = cv.transform([source])\n",
    "print(\"행렬 크기: \", source_cv.shape)\n",
    "\n",
    "# source_cv와 기존 벡터간의 similarity 계산\n",
    "# 즉, 첫번째 리뷰와 전체 리뷰 데이터 간 유사도 계산\n",
    "sim = cosine_similarity(source_cv, reviews_cv)\n",
    "\n",
    "print(\"유사도 행렬 크기: \", sim.shape)\n",
    "print(sorted(sim[0], reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "088f6f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 유사한 리뷰의 인덱스:  0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"가장 유사한 리뷰의 인덱스: \", np.argmax(sim[0]))\n",
    "# 원본인 첫번째 리뷰와 일치함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "10735378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사도 행렬 크기:  (1000, 1000)\n",
      "[0.2154324687928984, 0.2083129401110336, 0.20689923977750496, 0.2051538511928547, 0.2036945654278849, 0.20053201319079753, 0.1999901221161402, 0.1998916225477669, 0.1992476013808293, 0.19857183053502356]\n"
     ]
    }
   ],
   "source": [
    "# 그냥 해보고 싶어서\n",
    "# 전체 리뷰 절반으로 나눠서 유사도 계산하기\n",
    "sample1 = reviews[:len(reviews)//2]\n",
    "sample2 = reviews[len(reviews)//2:]\n",
    "\n",
    "sample1_cv = CountVectorizer(max_features=1000)\n",
    "sample1_cv.fit(sample1)\n",
    "dtm1 = sample1_cv.transform(sample1)\n",
    "\n",
    "sample2_cv = CountVectorizer(max_features=1000)\n",
    "sample2_cv.fit(sample2)\n",
    "dtm2 = sample2_cv.transform(sample2)\n",
    "\n",
    "sim = cosine_similarity(dtm1, dtm2)\n",
    "print(\"유사도 행렬 크기: \", sim.shape)\n",
    "print(sorted(sim[5], reverse=True)[:10])    # 6번째 댓글과 유사도가 가장 높은 10개 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "69b61426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810\n",
      "6번째 댓글:  capsule : in 2176 on the planet mars police taking into custody an accused murderer face the title menace . \n",
      "there is a lot of fighting and not a whole lot of story otherwise . \n",
      "john carpenter reprises so many ideas from his previous films , especially assault on precinct 13 , that the new film comes off as his homage to himself . \n",
      " , 0 ( -4 to +4 ) . \n",
      "john carpenter apparently believes that action scenes in which people fight something horrible are the same as horror scenes . \n",
      "for a writer and \n",
      "유사도가 그나마 높은 810번 댓글:  i admit it . \n",
      "i thought arnold schwarzenegger had a knack for comedy when he made twins and true lies . \n",
      "watching him in jingle all the way , i wondered why anyone ever thought he could carry such a lame movie targeted at susceptible kids . \n",
      "it was one thing to scare the crap out of kids with the pg-13 kindergarten cop , but parents who let small children see this movie will have to explain themes of violence , alcohol consumption , burglary , racism and child molestation . \n",
      "and you know they'll\n"
     ]
    }
   ],
   "source": [
    "# 6번째 댓글과 유사도가 가장 높은 댓글 인덱스\n",
    "print(np.argmax(sim[5]))\n",
    "\n",
    "print(\"5번 댓글: \", reviews[5][:500])\n",
    "print(\"유사도가 그나마 높은 810번 댓글: \", reviews[810][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d97240",
   "metadata": {},
   "source": [
    "<br/> <br/>\n",
    "## TF-IDF\n",
    "### 문서에서 너무 자주 나타나는 단어의 중요도를 낮춤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "45585554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 리뷰 카운트 벡터에서 20개 출력:  [10  0  0  2  0  0  0  0  0  0  0  1  0  0  2  0  2  2  0  0]\n",
      "첫 번째 리뷰 tfidf 벡터에서 20개 출력:  [0.36352951 0.         0.         0.02838787 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.02536173\n",
      " 0.         0.         0.04851355 0.         0.03515255 0.05097422\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# 1. TfidfTransformer - 카운트 벡터로부터 변환\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "transformer = TfidfTransformer()\n",
    "\n",
    "reviews_tfidf = transformer.fit_transform(reviews_cv)\n",
    "\n",
    "print(\"첫 번째 리뷰 카운트 벡터에서 20개 출력: \", reviews_cv[0].toarray()[0][:20])\n",
    "print(\"첫 번째 리뷰 tfidf 벡터에서 20개 출력: \", reviews_tfidf[0].toarray()[0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214a1748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
