{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e4b0361",
   "metadata": {},
   "source": [
    "# 다음 영화 리뷰 댓글로 영화 제목 예측하기\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad87335f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>돈 들인건 티가 나지만 보는 내내 하품만</td>\n",
       "      <td>1</td>\n",
       "      <td>2018.10.29</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.</td>\n",
       "      <td>10</td>\n",
       "      <td>2018.10.26</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...</td>\n",
       "      <td>8</td>\n",
       "      <td>2018.10.24</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이 정도면 볼만하다고 할 수 있음!</td>\n",
       "      <td>8</td>\n",
       "      <td>2018.10.22</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>재미있다</td>\n",
       "      <td>10</td>\n",
       "      <td>2018.10.20</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating        date  \\\n",
       "0                             돈 들인건 티가 나지만 보는 내내 하품만       1  2018.10.29   \n",
       "1       몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.      10  2018.10.26   \n",
       "2  이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...       8  2018.10.24   \n",
       "3                                이 정도면 볼만하다고 할 수 있음!       8  2018.10.22   \n",
       "4                                               재미있다      10  2018.10.20   \n",
       "\n",
       "    title  \n",
       "0  인피니티 워  \n",
       "1  인피니티 워  \n",
       "2  인피니티 워  \n",
       "3  인피니티 워  \n",
       "4  인피니티 워  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/daum_movie_review.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f02dd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14725\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83cd28f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "신과함께      4947\n",
       "택시운전사     2322\n",
       "인피니티 워    2042\n",
       "범죄도시      1939\n",
       "곤지암       1547\n",
       "라라랜드      1150\n",
       "코코         778\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'].value_counts()\n",
    "# '신과함께'와 '코코'의 개수 차이가 많이 남 -> 불균형 데이터셋(Imbalanced dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73617c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  11043\n",
      "Test size:  3682\n"
     ]
    }
   ],
   "source": [
    "# train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 비율 지정하지 않으면 train:test = 75:25로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['title'], random_state=0)\n",
    "\n",
    "print(\"Train size: \", len(X_train))\n",
    "print(\"Test size: \", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cd7d9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['이전', '작품', '에', '비해', '더', '화려하고', '스케일', '도', '커졌지만', '....', '전국', '맛집', '의', '음식', '들', '을', '한데', '모은', '것', '까지는', '좋았으나', '이', '걸', '모두', '한', '그릇', '에', '섞어', '버린', '듯', '한', '느낌', '...', '그래도', '다음', '작품', '을', '기대하게', '만든다', '...']\n",
      "['이전', '작품', '더', '스케일', '전국', '맛집', '음식', '것', '걸', '모두', '그릇', '듯', '느낌', '다음', '작품']\n"
     ]
    }
   ],
   "source": [
    "# 형태소 분석\n",
    "from konlpy.tag import Okt\n",
    "t = Okt()\n",
    "\n",
    "print(t.morphs(X_train[2]))   # 형태소\n",
    "print(t.nouns(X_train[2]))    # 명사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c95c05cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf로 특성 추출\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# t.nouns를 토크나이저로 지정\n",
    "tfidf = TfidfVectorizer(tokenizer=t.nouns, max_features=2000, min_df=5, max_df=0.5)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4b8a6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.756\n",
      "Test score: 0.694\n"
     ]
    }
   ],
   "source": [
    "# 로지스틱 회귀분석\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)  \n",
    "\n",
    "lr.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"Train score: {:.3f}\".format(lr.score(X_train_tfidf, y_train)))\n",
    "print(\"Test score: {:.3f}\".format(lr.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d80648ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제 영화 제목 | 예측한 제목 | 리뷰\n",
      "0.65\n",
      "('범죄도시', '신과함께', '오랜만에 잼나는 영화 봤습니다.  다음에 더 재미있는 영화 기대하겠습니다.')\n",
      "\n",
      "('범죄도시', '범죄도시', '조연들이 눈에 박힌다. 간만에 집중 ㅎ')\n",
      "\n",
      "('코코', '코코', '대감동을 선사. 인사이드 아웃을 잇는 픽사의 감동스토리. 신과함께의 멕시코판이라고나할까요??')\n",
      "\n",
      "('신과함께', '신과함께', '돈이 안아까웠던 영화ᆞᆞ  정말 좋았다')\n",
      "\n",
      "('신과함께', '신과함께', '역시 김용화감독이 영화는 잘 만들어요. 이제 VFX 제작 부문도 헐리우드 수준 이상입니다.')\n",
      "\n",
      "('택시운전사', '택시운전사', '민주화를 위해 힘써주신 분들께 감사하는 마음으로 살아야겠다.')\n",
      "\n",
      "('신과함께', '신과함께', '잠만 자다 왔음')\n",
      "\n",
      "('신과함께', '신과함께', '오랜만에 잼있고 좋은 영화를 봤다')\n",
      "\n",
      "('범죄도시', '신과함께', '잼남')\n",
      "\n",
      "('범죄도시', '인피니티 워', '대박~~')\n",
      "\n",
      "('인피니티 워', '인피니티 워', '불과 며칠전에 저스티스리그봤는데...............10점을 안 줄 수가 없다.')\n",
      "\n",
      "('신과함께', '신과함께', '개인적으로 정말 재밌었다')\n",
      "\n",
      "('범죄도시', '신과함께', '극장에서 본 한국영화중, 첨으로  돈  안까움')\n",
      "\n",
      "('범죄도시', '범죄도시', '비스티보이즈  흥행은 못했지만 영화 속의 윤계상씨가 참 매력적이다 생각했는데  이번에 정말 자기 옷을 입었다는 생각이 듭니다 윤계상이라는 배우는 자상함 속에 마초성이 있다는 생각이 들었었는데 유감없이 그 숨어있던 마초적 매력이 포텐이 터진것 같아요')\n",
      "\n",
      "('인피니티 워', '곤지암', '이 영화를 보니 디씨코믹스 영화들은 코흘리개라고 느끼게 되었다..')\n",
      "\n",
      "('택시운전사', '신과함께', '시도는 좋았으나 결과는 참옥하다.')\n",
      "\n",
      "('택시운전사', '신과함께', '좋은 영화입니다')\n",
      "\n",
      "('신과함께', '신과함께', '보면서  좀  지루하기도 하고 . . . 그런데  그렇게 슬프지 않았는데도  목이  메는건 뭔지 . . .')\n",
      "\n",
      "('범죄도시', '범죄도시', '믿고보는 마동석')\n",
      "\n",
      "('신과함께', '신과함께', '어제 봣습니다 크게 잼있진 않으나 그렇다고 그렇게 재미 없지도 않습니다 그럭저럭 볼만 했구요 우리나라 CG가 많이 좋아졌구나 하는걸 느꼈구요..음..마지막엔 슬픕니다.. 펑펑 울었습니다 ..ㅠㅠ ㅎㅎ')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"실제 영화 제목 | 예측한 제목 | 리뷰\")\n",
    "\n",
    "for c in zip(y_test[:20], lr.predict(X_test_tfidf[:20]), X_test[:20]):\n",
    "    print(c)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c773b8d3",
   "metadata": {},
   "source": [
    "# 성능 개선 방법\n",
    "## 1. 토큰화\n",
    "- 명사, 동사, 형용사로 토큰화\n",
    "- 형태소 토큰화\n",
    "\n",
    "## 2. 다른 분류 방법 사용\n",
    "- 릿지 회귀, 라쏘 회귀\n",
    "- 나이브 베이즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c280c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 토큰화\n",
    "# 명사, 동사, 형용사를 이용해 토큰화\n",
    "def twit_tokenizer(text):\n",
    "    tags = ['Noun', 'Verb', 'Adjective']\n",
    "    result = []\n",
    "    \n",
    "    for word, tag in t.pos(text, norm=True, stem=True):       # 품사 태깅\n",
    "        if tag in tags:\n",
    "            result.append(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c6661bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.784\n",
      "Test score: 0.712\n"
     ]
    }
   ],
   "source": [
    "# tfidf에 토크나이저로 지정\n",
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, max_features=2000, min_df=5, max_df=0.5)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# 로지스틱 회귀분석\n",
    "lr = LogisticRegression(max_iter=1000)  \n",
    "\n",
    "lr.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"Train score: {:.3f}\".format(lr.score(X_train_tfidf, y_train)))\n",
    "print(\"Test score: {:.3f}\".format(lr.score(X_test_tfidf, y_test)))\n",
    "# 명사 토큰화보다 성능이 향상 0.695 -> 0.712"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8175b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['몰입/Noun', '하다/Verb', '없다/Adjective', './Punctuation', '어렵다/Adjective', '생각/Noun', '하다/Verb', '필요없다/Adjective', './Punctuation', '내/Noun', '가/Josa', '전투/Noun', '에/Josa', '참여/Noun', '한/Determiner', '듯/Noun', '손/Noun', '에/Josa', '땀/Noun', '이남/Noun', './Punctuation']\n"
     ]
    }
   ],
   "source": [
    "# 형태소 단위로 토큰화\n",
    "def twit_tokenizer2(text):\n",
    "    result = []\n",
    "    for word ,tag in t.pos(text, norm=True, stem=True):\n",
    "        result.append('/'.join([word, tag]))\n",
    "    return result\n",
    "\n",
    "print(twit_tokenizer2(X_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76a178b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.789\n",
      "Test score: 0.718\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer2, max_features=2000, min_df=5, max_df=0.5)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# 로지스틱 회귀분석\n",
    "lr = LogisticRegression(max_iter=1000)  \n",
    "\n",
    "lr.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"Train score: {:.3f}\".format(lr.score(X_train_tfidf, y_train)))\n",
    "print(\"Test score: {:.3f}\".format(lr.score(X_test_tfidf, y_test)))\n",
    "# 성능 향상 0.712 -> 0.718"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eedff624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['몰입/Noun', '하다/Verb', '없다/Adjective', '어렵다/Adjective', '생각/Noun', '하다/Verb', '필요없다/Adjective', '내/Noun', '전투/Noun', '참여/Noun', '듯/Noun', '손/Noun', '땀/Noun', '이남/Noun']\n"
     ]
    }
   ],
   "source": [
    "# 명사, 동사, 형용사에 품사 태깅을 하면?\n",
    "def twit_tokenizer3(text):\n",
    "    tags = ['Noun', 'Verb', 'Adjective']\n",
    "    result = []\n",
    "    for word ,tag in t.pos(text, norm=True, stem=True):\n",
    "        if tag in tags:\n",
    "            result.append('/'.join([word, tag]))\n",
    "    return result\n",
    "\n",
    "print(twit_tokenizer3(X_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ddbbf3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.784\n",
      "Test score: 0.713\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer3, max_features=2000, min_df=5, max_df=0.5)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# 로지스틱 회귀분석\n",
    "lr = LogisticRegression(max_iter=1000)  \n",
    "\n",
    "lr.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"Train score: {:.3f}\".format(lr.score(X_train_tfidf, y_train)))\n",
    "print(\"Test score: {:.3f}\".format(lr.score(X_test_tfidf, y_test)))\n",
    "# 성능이 그닥 나아지진 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5545fe46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max alpha 1.600 at max validation score 0.727\n"
     ]
    }
   ],
   "source": [
    "# 2. 다른 분류 방법 사용\n",
    "# 릿지 회귀\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "X_train_ridge, X_val_ridge, y_train_ridge, y_val_ridge = train_test_split(\n",
    "    X_train_tfidf, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "max_score = 0\n",
    "max_alpha = 0\n",
    "\n",
    "# 최적 alpha를 찾기 위해 그리드 서치\n",
    "for alpha in np.arange(0.1, 10, 0.1):\n",
    "    \n",
    "    ridge_clf = RidgeClassifier(alpha=alpha)\n",
    "    ridge_clf.fit(X_train_ridge, y_train_ridge) \n",
    "    score = ridge_clf.score(X_val_ridge, y_val_ridge) #검정 데이터셋에 대해 정확도를 측정\n",
    "    \n",
    "    if score > max_score:\n",
    "        max_score = score\n",
    "        max_alpha = alpha\n",
    "        \n",
    "print('Max alpha {:.3f} at max validation score {:.3f}'.format(max_alpha, max_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "644373cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.807\n",
      "Test score: 0.726\n",
      "Train score: 0.703\n",
      "Test score: 0.696\n",
      "Used features count: 956 out of 2000\n"
     ]
    }
   ],
   "source": [
    "# 찾은 alpha로 릿지 회귀\n",
    "ridge_clf = RidgeClassifier(alpha=1.6)\n",
    "ridge_clf.fit(X_train_tfidf, y_train)\n",
    "print('Train score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))\n",
    "\n",
    "# 라쏘 회귀\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "lasso_clf = LogisticRegression(penalty='l1', solver='liblinear', C=0.5)\n",
    "lasso_clf.fit(X_train_tfidf, y_train)\n",
    "print('Train score: {:.3f}'.format(lasso_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test score: {:.3f}'.format(lasso_clf.score(X_test_tfidf, y_test)))\n",
    "print('Used features count: {}'.format(np.sum(lasso_clf.coef_ != 0)), 'out of', X_train_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eaaa74a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.768\n",
      "Test score: 0.704\n"
     ]
    }
   ],
   "source": [
    "# 나이브 베이즈\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NB = MultinomialNB(alpha=0.1)\n",
    "NB.fit(X_train_tfidf, y_train)\n",
    "print('Train score: {:.3f}'.format(NB.score(X_train_tfidf, y_train)))\n",
    "print('Test score: {:.3f}'.format(NB.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07520974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
